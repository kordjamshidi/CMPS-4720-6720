#!/bin/bash
# Data Pipeline
#run in terminal with “./pipeline.txt”
echo “Running Data Pipeline”

#removes existing images and begins replacing them
#rm -rf image_folder



#  make images
#  produces (overwrites) annotations_all.csv
echo “Data Augmentation”
python data_augmentation.py


#  learn features; output features to npy files
#  output: feature vector matrix
#	    filename matrix
#  both matrices are in the same order filename[x] is the name of feature_vector[x]
echo “Feature Extraction”  
python feature_extraction.py


#  runs SVM on features
#    hold different image set as test case for each iteration
#    run multiple kernels
#    outputs results as csv files
echo “Running SVM”
python model1.py